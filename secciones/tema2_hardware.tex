% ============================================================
%  TEMA 2 — Relación entre la ampliación de memoria y la
%           implementación del modelo relacional
% ============================================================
\chapter{Relación entre el avance del hardware y la implementación del modelo relacional}

\section{La memoria como cuello de botella}

El modelo relacional de Codd era teóricamente correcto desde 1970. El problema no era la teoría sino el costo de ejecutarla. Las operaciones que requiere el modelo relacional, joins entre tablas, ordenamientos, índices dinámicos, son intensivas en memoria. Y en los años 70, la memoria principal era de núcleos de ferrita, carísima y medida en kilobytes.

En ese contexto, un sistema que necesitara mantener grandes estructuras en RAM para funcionar correctamente simplemente no era viable para la mayoría de las organizaciones. Los modelos jerárquico y en red, con sus punteros físicos predefinidos, consumían mucho menos memoria porque no necesitaban razonar sobre los datos: simplemente los seguían.

\section{Evolución de la memoria principal}

La transición llegó con los chips DRAM, que permitieron mayor densidad a menor costo. Pasar de kilobytes en los años 70 a megabytes en los 80 y luego a gigabytes en los servidores modernos cambió completamente lo que era posible hacer en un SGBD \parencite{hennessy_patterson_2017}.

Esa memoria adicional es lo que permitió construir componentes como el buffer cache de Oracle o el \texttt{shared\_buffers} de PostgreSQL: áreas grandes en RAM donde los datos más usados viven sin tener que ir al disco en cada consulta. Sin esa memoria disponible, esos componentes no tienen sentido.

\section{Evolución del almacenamiento secundario}

El almacenamiento también evolucionó, aunque por razones distintas. El IBM RAMAC de 1956 almacenaba 5 MB en un dispositivo del tamaño de una heladera. Hoy los terabytes son comunes y económicos, pero más relevante que la capacidad fue la reducción de latencia.

El salto de HDD a SSD impactó directamente componentes como los redo logs, donde la velocidad de escritura es crítica. Si escribir al log se convierte en un cuello de botella, todas las transacciones esperan. Con SSD, ese problema se redujo significativamente \parencite{oracle_admin_19c}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.92\textwidth]{img/fig2_hardware}
  \caption{Relación entre el crecimiento de la RAM disponible y la adopción del modelo relacional (estimación ilustrativa).}
  \label{fig:hardware}
\end{figure}

\section{Cómo el hardware habilitó el modelo relacional}

\subsection{Buffers más grandes}

Con más RAM disponible, los gestores podían mantener más datos en memoria y reducir los accesos físicos al disco. Esto es especialmente importante para consultas con múltiples joins, que en los años 70 eran computacionalmente inviables no porque el algoritmo fuera incorrecto, sino porque no había donde ejecutarlo \parencite{silberschatz_2019}.

\subsection{Caché de planes de consulta}

Con suficiente memoria también fue posible guardar los planes de ejecución ya calculados. Una consulta frecuente no tiene que recompilarse cada vez que se ejecuta. En sistemas con miles de transacciones por segundo, esa diferencia es significativa. Es la lógica detrás del Shared Pool de Oracle y del Plan Cache de SQL Server \parencite{oracle_concepts_19c}.

\subsection{Operaciones en memoria}

Operaciones como hash joins o sort-merge joins pueden ejecutarse directamente en RAM cuando hay espacio. Si no lo hay, el gestor las desborda a disco temporal, con el impacto en rendimiento que eso implica. La disponibilidad de memoria es lo que determina en cuál de los dos escenarios cae una consulta compleja \parencite{ramakrishnan_2003}.

\subsection{Índices más complejos}

Los índices B-Tree necesitan cargarse en memoria para ser útiles. Un índice que vive permanentemente en disco pierde gran parte de su ventaja porque acceder a él cuesta casi lo mismo que escanear la tabla. Con más RAM disponible fue posible mantener índices más grandes y complejos en memoria, lo que se tradujo en búsquedas mucho más rápidas.

\section{El factor económico}

La adopción masiva no fue solo un fenómeno técnico. En los años 70, el hardware necesario para que Oracle funcionara correctamente era prohibitivamente caro. El cambio ocurrió en los años 80, cuando los precios cayeron lo suficiente para que los servidores relacionales pasaran de ser accesibles solo para grandes corporaciones a algo viable para organizaciones medianas \parencite{hene}. La teoría no cambió; cambió quién podía pagarla.

\section{Impacto en transacciones y concurrencia}

La arquitectura que hace posibles las propiedades ACID también depende del hardware. Más RAM permite gestionar tablas de bloqueos más grandes en memoria, lo que se traduce en soporte para más usuarios simultáneos. Y discos más rápidos permiten que los redo logs se escriban con latencia mínima, que es la condición necesaria para que la durabilidad no sea solo un concepto teórico \parencite{gray_reuter_1992}.